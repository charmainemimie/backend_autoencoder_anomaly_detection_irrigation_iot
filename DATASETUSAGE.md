# Dataset Usage - Clear Explanation

## ğŸ¯ Simple Answer

### **For TRAINING and VALIDATION: Normal Data Only**
### **For TESTING: Normal Data + Attack Data**

---

## ğŸ“Š The Three Datasets

### **Dataset 1: Training Dataset (NORMAL DATA ONLY)**

**File**: `soil_sensor_data.csv`  
**Generated by**: `generate_kenya_dataset.py`  
**Size**: 17,000 samples  
**Content**: ALL NORMAL sensor readings (no attacks)

```
Columns:
- soil_moisture (%)
- soil_temperature (Â°C)
- irrigation_valve_flow_rate (L/min)
- irrigation_type
- timestamp
- sensor_id
```

**What's in it**:
- âœ… Legitimate sensor readings from normal farm operations
- âœ… Seasonal variations (rainy/dry seasons)
- âœ… Day/night patterns
- âœ… Two crop types (Maize, Tomatoes)
- âŒ NO attacks
- âŒ NO spoofing
- âŒ NO manipulation

**Purpose**: Train autoencoder to learn what "NORMAL" looks like

---

### **Dataset 2: Validation Set (SUBSET OF NORMAL DATA)**

**File**: Automatically split from `soil_sensor_data.csv`  
**Size**: 2,550 samples (15% of 17,000)  
**Content**: NORMAL data only (never seen during training)

**Purpose**: 
1. Set the anomaly detection threshold
2. Calculate the 95th percentile of reconstruction errors on normal data
3. This threshold = boundary between "normal" and "attack"

**Used in**: `train_model.py` - Phase 2 (Validation Phase)

```python
# In train_model.py
X_train, X_val, X_test = split(normal_data, 70%, 15%, 15%)

# Calculate errors on validation set (all normal)
val_errors = [0.0123, 0.0145, 0.0167, ..., 0.0456]

# Set threshold
threshold = percentile(val_errors, 95) = 0.0456

# Interpretation: 95% of NORMAL data has error < 0.0456
#                 Anything above this = ATTACK
```

---

### **Dataset 3: Test Set (NORMAL + CYBER-ATTACKS)**

**File**: `test_dataset_with_attacks.csv`  
**Generated by**: `generate_test_dataset_with_anomalies.py`  
**Size**: 2,500 samples  
**Content**: 2,000 normal + 500 LABELED cyber-attacks

```
Composition:
â”œâ”€ 2,000 samples (80%) - NORMAL/BENIGN
â”‚  â””â”€ Legitimate sensor readings (same distribution as training)
â”‚
â””â”€ 500 samples (20%) - CYBER-ATTACKS
   â”œâ”€ Data Injection (Low) - 100 samples
   â”œâ”€ Data Injection (High) - 80 samples
   â”œâ”€ Sensor Spoofing/Replay - 90 samples
   â”œâ”€ Man-in-the-Middle Modification - 80 samples
   â”œâ”€ Sensor Value Manipulation - 70 samples
   â”œâ”€ Protocol Exploitation - 40 samples
   â””â”€ DoS/Sensor Jamming - 40 samples
```

**Columns**:
```csv
soil_moisture,soil_temperature,is_attack,attack_type,attack_vector,sample_id
42.5,25.3,0,normal,none,BENIGN_0001
18.2,36.7,1,data_injection_low,MITM on sensor data,ATTACK_DATA_INJECTION_LOW_0042
```

**What's in the ATTACK samples**:

#### **Attack Type 1: Data Injection (Low Moisture)**
```
Legitimate Reading: moisture=45%, temp=25Â°C
Attacker Injects:   moisture=15%, temp=25Â°C  â† FALSE low moisture
Result:             Valve opens unnecessarily â†’ wastes water
Detection:          High reconstruction error (model expects ~45%, sees 15%)
```

#### **Attack Type 2: Data Injection (High Moisture)**
```
Legitimate Reading: moisture=30%, temp=28Â°C  â† Needs irrigation!
Attacker Injects:   moisture=65%, temp=28Â°C  â† FALSE high moisture
Result:             Valve stays closed â†’ crops die from drought
Detection:          High reconstruction error (model expects ~30%, sees 65%)
```

#### **Attack Type 3: Sensor Spoofing/Replay**
```
Current Reality:    moisture=25%, temp=32Â°C  â† Critical irrigation needed
Attacker Replays:   moisture=50%, temp=22Â°C  â† Old data from 2 days ago
Result:             System thinks conditions are fine â†’ no irrigation
Detection:          Values don't match learned patterns for this time/season
```

#### **Attack Type 4: Man-in-the-Middle**
```
Sensor Sends:       moisture=45%, temp=25Â°C
MITM Modifies:      moisture=20%, temp=38Â°C  â† Changed in transit
Gateway Receives:   moisture=20%, temp=38Â°C
Result:             Wrong irrigation decisions
Detection:          Modified values outside normal correlation patterns
```

#### **Attack Type 5: Physical Manipulation**
```
Real Soil:          moisture=40%, temp=24Â°C
Tampered Sensor:    moisture=15%, temp=35Â°C  â† Physically rewired
Result:             False readings trigger wrong actions
Detection:          Impossible combination (autoencoder learned correlations)
```

**How attacks affect valve**:
```python
# Normal Operation
if moisture < 30% OR temperature > 32Â°C:
    open_valve(calculate_flow_rate())
else:
    close_valve()

# Attack Scenario 1: Inject LOW moisture
Real: moisture=45% â†’ valve should be CLOSED
Injected: moisture=15% â†’ valve OPENS (wasting water) âœ—

# Attack Scenario 2: Inject HIGH moisture  
Real: moisture=20% â†’ valve should be OPEN
Injected: moisture=70% â†’ valve stays CLOSED (crops die) âœ—
```

**Purpose**: 
1. Measure TRUE attack detection performance
2. Calculate real accuracy, precision, recall
3. Determine which attack types are detected/missed
4. Validate the model works in production

**Used in**: `evaluate_with_labeled_data.py`

---

## ğŸ”„ Complete Workflow

### **Phase 1: Data Generation**

```bash
# Generate 17,000 NORMAL samples for training
python generate_data.py
# Output: soil_sensor_data.csv (ALL NORMAL)
```

### **Phase 2: Model Training**

```bash
python train_model.py
```

**What happens**:
```
1. Load soil_sensor_data.csv (17,000 NORMAL samples)
   
2. Split automatically inside train_model.py:
   â”œâ”€ Training:   11,900 (70%) - Learn normal patterns
   â”œâ”€ Validation:  2,550 (15%) - Set threshold
   â””â”€ Test:        2,550 (15%) - Check overfitting
   
   âš ï¸ ALL THREE SETS CONTAIN ONLY NORMAL DATA
   
3. Training Phase:
   - Autoencoder learns to reconstruct normal moisture & temp patterns
   - Learns correlation: low moisture + high temp â†’ valve should open
   
4. Validation Phase:
   - Calculate reconstruction errors on 2,550 normal samples
   - Set threshold at 95th percentile: 0.0456
   - Interpretation: Errors > 0.0456 = ATTACK
   
5. Internal Test Phase:
   - Test on 2,550 normal samples
   - Verify model doesn't overfit
   - âš ï¸ This is NOT a real attack detection test!
```

**Output**:
- `autoencoder_model.h5` - Trained model
- `scaler.pkl` - Feature scaler
- `model_metrics.json` - Contains threshold value
- Threshold: 0.0456 (example)

### **Phase 3: Attack Dataset Generation**

```bash
# Generate 2,500 samples: 2,000 normal + 500 ATTACKS
python generate_test_dataset_with_anomalies.py
# Output: test_dataset_with_attacks.csv (LABELED ATTACKS)
```

**What it creates**:

**Normal Samples (2,000)**:
```
moisture=42%, temp=25Â°C, is_attack=0, attack_type=normal
moisture=38%, temp=27Â°C, is_attack=0, attack_type=normal
moisture=45%, temp=23Â°C, is_attack=0, attack_type=normal
...
```

**Attack Samples (500)**:
```
# Data Injection Low
moisture=12%, temp=26Â°C, is_attack=1, attack_type=data_injection_low

# Data Injection High  
moisture=75%, temp=23Â°C, is_attack=1, attack_type=data_injection_high

# Replay Attack
moisture=50%, temp=20Â°C, is_attack=1, attack_type=sensor_spoofing_replay

# MITM
moisture=18%, temp=39Â°C, is_attack=1, attack_type=man_in_the_middle_modify

# Physical Tampering
moisture=10%, temp=42Â°C, is_attack=1, attack_type=sensor_value_manipulation
...
```

### **Phase 4: True Attack Detection Evaluation**

```bash
python evaluate_with_labeled_data.py
```

**What happens**:
```
1. Load trained model + threshold (0.0456)
2. Load test_dataset_with_attacks.csv (2,000 normal + 500 attacks)
3. For each sample:
   - Calculate reconstruction error
   - If error > 0.0456 â†’ Predict ATTACK
   - If error â‰¤ 0.0456 â†’ Predict NORMAL
4. Compare predictions vs TRUE labels
5. Calculate REAL metrics
```

**Example predictions**:

```
Sample 1:
  Input: moisture=42%, temp=25Â°C, TRUE_LABEL=normal
  Reconstruction: moisture=42.1%, temp=25.2Â°C
  Error: 0.0189
  Prediction: 0.0189 â‰¤ 0.0456 â†’ NORMAL âœ“ CORRECT

Sample 2:
  Input: moisture=15%, temp=38Â°C, TRUE_LABEL=attack (injection)
  Reconstruction: moisture=43%, temp=26Â°C â† Model tries to "fix" to normal
  Error: 0.2847 â† HUGE error!
  Prediction: 0.2847 > 0.0456 â†’ ATTACK âœ“ DETECTED

Sample 3:
  Input: moisture=48%, temp=24Â°C, TRUE_LABEL=normal
  Reconstruction: moisture=47.8%, temp=24.3Â°C
  Error: 0.0623
  Prediction: 0.0623 > 0.0456 â†’ ATTACK âœ— FALSE ALARM

Sample 4:
  Input: moisture=28%, temp=31Â°C, TRUE_LABEL=attack (MITM)
  Reconstruction: moisture=40%, temp=26Â°C
  Error: 0.0412
  Prediction: 0.0412 â‰¤ 0.0456 â†’ NORMAL âœ— MISSED ATTACK
```

**Output**: `evaluation_results_labeled.json`

```json
{
  "overall_metrics": {
    "accuracy": 0.94,      // 94% correct classifications
    "precision": 0.85,     // 85% of alarms are real attacks
    "recall": 0.78,        // Catches 78% of attacks
    "f1_score": 0.81
  },
  "per_attack_type": {
    "data_injection_low": {
      "detection_rate": 0.95,  // 95% of this attack type detected
      "count": 100
    },
    "data_injection_high": {
      "detection_rate": 0.88,
      "count": 80
    },
    ...
  }
}
```

---

## ğŸ“Š Visual Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRAINING DATA (soil_sensor_data.csv - 17,000 samples)         â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                  â”‚
â”‚  Split by train_model.py:                                       â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ TRAINING SET (70% = 11,900 samples)                    â”‚    â”‚
â”‚  â”‚ Purpose: Learn what NORMAL looks like                  â”‚    â”‚
â”‚  â”‚ Content: Legitimate moisture, temp, valve readings     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ VALIDATION SET (15% = 2,550 samples)                   â”‚    â”‚
â”‚  â”‚ Purpose: Set anomaly threshold (95th percentile)       â”‚    â”‚
â”‚  â”‚ Content: Normal data â†’ threshold = 0.0456              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ INTERNAL TEST (15% = 2,550 samples)                    â”‚    â”‚
â”‚  â”‚ Purpose: Check overfitting                             â”‚    â”‚
â”‚  â”‚ Content: Normal data (NOT for attack detection!)       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  âš ï¸  ALL DATA IS NORMAL - No attacks included               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                            â†“ MODEL TRAINED â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ATTACK TEST DATA (test_dataset_with_attacks.csv - 2,500)      â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ NORMAL/BENIGN (80% = 2,000 samples)                    â”‚    â”‚
â”‚  â”‚ Label: is_attack = 0                                   â”‚    â”‚
â”‚  â”‚ Purpose: Measure false positive rate                   â”‚    â”‚
â”‚  â”‚ Content: Legitimate readings (same as training dist)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ CYBER-ATTACKS (20% = 500 samples)                      â”‚    â”‚
â”‚  â”‚ Label: is_attack = 1                                   â”‚    â”‚
â”‚  â”‚ Purpose: Measure true detection rate                   â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚ Attack Types:                                          â”‚    â”‚
â”‚  â”‚ â€¢ Data Injection (Low moisture) - 100 samples          â”‚    â”‚
â”‚  â”‚ â€¢ Data Injection (High moisture) - 80 samples          â”‚    â”‚
â”‚  â”‚ â€¢ Sensor Spoofing/Replay - 90 samples                  â”‚    â”‚
â”‚  â”‚ â€¢ Man-in-the-Middle - 80 samples                       â”‚    â”‚
â”‚  â”‚ â€¢ Physical Manipulation - 70 samples                   â”‚    â”‚
â”‚  â”‚ â€¢ Protocol Exploitation - 40 samples                   â”‚    â”‚
â”‚  â”‚ â€¢ DoS/Jamming - 40 samples                             â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚ Each attack manipulates moisture/temp readings         â”‚    â”‚
â”‚  â”‚ which directly affects valve control decisions         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  âœ… CONTAINS LABELED ATTACKS - Real evaluation possible     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Key Points

### **1. Validation Set = Normal Data Only**
- âœ… Used to set threshold
- âœ… 2,550 samples from training dataset
- âœ… Tells us what "normal" reconstruction error looks like
- âŒ NOT used for attack detection testing

### **2. Internal Test Set = Normal Data Only**
- âœ… Used to check model doesn't overfit
- âœ… 2,550 samples from training dataset
- âŒ NOT a real attack detection test
- âŒ Metrics here are SIMULATED

### **3. Attack Test Set = Normal + Attacks**
- âœ… Separate dataset with LABELED attacks
- âœ… 2,000 normal + 500 cyber-attacks
- âœ… TRUE attack detection evaluation
- âœ… Real precision, recall, detection rates

### **4. Why This Approach?**

**Standard Practice for Autoencoder Anomaly Detection**:
```
TRAINING:   Learn from normal data only âœ“
VALIDATION: Set threshold on normal data âœ“  
TESTING:    Evaluate on normal + labeled attacks âœ“
```

**NOT like supervised learning**:
```
WRONG: Train on normal + attacks together âœ—
WRONG: Validate on attacks âœ—
```

---

## ğŸ” How Attacks Affect Valve

### **Normal Operation**
```python
# Legitimate sensor readings
moisture = 35%
temperature = 28Â°C

# Valve decision
if moisture < 30% OR temperature > 32Â°C:
    valve_status = OPEN
    flow_rate = calculate_needed_water()
else:
    valve_status = CLOSED
    flow_rate = 0

# Result: Valve CLOSED (conditions are okay)
```

### **Attack Scenario 1: Data Injection (Low)**
```python
# Attacker injects FALSE low moisture
REAL_moisture = 35%        # Actually okay
INJECTED_moisture = 12%    # FALSE reading

# Valve decision (based on FALSE data)
if 12% < 30%:              # TRUE (based on false data)
    valve_status = OPEN    # Opens unnecessarily!
    flow_rate = 25 L/min   # High flow

# Result: WASTED WATER, increased costs
# Detection: Model expects ~35%, sees 12% â†’ HIGH ERROR â†’ ATTACK!
```

### **Attack Scenario 2: Data Injection (High)**
```python
# Attacker injects FALSE high moisture
REAL_moisture = 20%        # Needs irrigation!
INJECTED_moisture = 70%    # FALSE reading

# Valve decision (based on FALSE data)
if 70% < 30%:              # FALSE
    valve_status = CLOSED  # Stays closed!
    flow_rate = 0

# Result: CROP FAILURE from drought
# Detection: Model expects ~20%, sees 70% â†’ HIGH ERROR â†’ ATTACK!
```

### **Attack Scenario 3: Correlated Manipulation**
```python
# Attacker modifies BOTH sensors
REAL: moisture=25%, temp=32Â°C  # Critical: needs irrigation
FAKE: moisture=55%, temp=22Â°C  # Looks "perfect"

# Valve decision
if 55% < 30% OR 22Â°C > 32Â°C:   # Both FALSE
    valve_status = CLOSED       # No irrigation!

# Result: CROP STRESS, potential failure
# Detection: Combination (55%, 22Â°C) doesn't match learned correlations
#            Model learned: low moisture + high temp often together
#            Seeing: high moisture + low temp â†’ UNUSUAL â†’ HIGH ERROR â†’ ATTACK!
```

---

## âœ… Summary

| Dataset | Source | Size | Content | Purpose |
|---------|--------|------|---------|---------|
| **Training** | soil_sensor_data.csv | 11,900 (70%) | Normal only | Learn normal patterns |
| **Validation** | soil_sensor_data.csv | 2,550 (15%) | Normal only | Set threshold |
| **Internal Test** | soil_sensor_data.csv | 2,550 (15%) | Normal only | Check overfitting |
| **Attack Test** | test_dataset_with_attacks.csv | 2,500 | 2,000 normal + 500 attacks | TRUE evaluation |

**Attack Types**: Spoofing, Injection, Manipulation of moisture/temp sensors â†’ affects valve decisions

**Detection Method**: Autoencoder reconstruction error > threshold â†’ ATTACK DETECTED

---

**Bottom Line**: Train and validate on normal data, then test on a separate dataset with labeled cyber-attacks to get TRUE detection performance! ğŸ¯